services:
  csv-to-postgres-producer:
    build:
      context: .
      dockerfile: csv-to-postgres-producer/Dockerfile
    image: csv-to-postgres-producer:0.1  
    depends_on:
      - postgres
    networks:
      - infra-net

  pgadmin:
    image: dpage/pgadmin4
    environment:
      PGADMIN_DEFAULT_EMAIL: postgres@postgres.com
      PGADMIN_DEFAULT_PASSWORD: postgres
    ports:
      - "5050:80" # "HOST_PORT:CONTAINER_PORT"
    depends_on:       
      - postgres
    networks:
      - infra-net

  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: postgres         
    ports:
      - "5432:5432"
    command: ["postgres", "-c", "wal_level=logical", "-c", "max_replication_slots=5", "-c", "max_wal_senders=7"]
    networks:
      - infra-net
    volumes:
      - postgres-data:/var/lib/postgresql/data

  zookeeper:
    image: confluentinc/cp-zookeeper:7.9.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ALLOW_ANONYMOUS_LOGIN: "yes"
    networks:
      - infra-net

  kafka:
    image: confluentinc/cp-kafka:7.9.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181      
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,INTERNAL://kafka:29092
      KAFKA_LISTENER_INTERFACE: INSIDE
      KAFKA_LISTENER_PORT: 9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,INTERNAL:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    depends_on:
      - zookeeper
    networks:
      - infra-net
    volumes:
      - kafka-logs:/var/lib/kafka/data

  kafka-connect:
    image: confluentinc/cp-kafka-connect:7.9.0
    container_name: kafka-connect
    ports:
      - "8083:8083"
    environment:
      # Bootstrap server for Kafka Connect (should be resolvable via Docker network)
      CONNECT_BOOTSTRAP_SERVERS: kafka:9092
      # REST API settings
      CONNECT_REST_PORT: 8083
      CONNECT_REST_ADVERTISED_HOST_NAME: kafka-connect
      # Unique group ID for distributed mode
      CONNECT_GROUP_ID: kafka-connect-group
      # Internal topics for storing configuration, offsets, and status
      CONNECT_CONFIG_STORAGE_TOPIC: kafka-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_STORAGE_TOPIC: kafka-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: kafka-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      # Required converters with schema support disabled (optional: disable schemas for simplicity)
      CONNECT_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
      CONNECT_KEY_CONVERTER_SCHEMAS_ENABLE: "false"
      CONNECT_VALUE_CONVERTER_SCHEMAS_ENABLE: "false"
      # Path where connector plugins are located
      CONNECT_PLUGIN_PATH: /usr/share/confluent-hub-components
    depends_on:
      - kafka
      - zookeeper
    networks:
      - infra-net
    volumes:
    - kafka-connect-data:/etc/kafka-connect
    command:
      - bash
      - -c
      - |
          echo "Installing Debezium Connector"
          confluent-hub install --no-prompt debezium/debezium-connector-postgresql:latest
          #
          echo "Launching Kafka Connect worker"
          /etc/confluent/docker/run &
          #
          sleep infinity

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      DYNAMIC_CONFIG_ENABLED: 'true'
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: connect
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect:8083
    depends_on:
      - kafka-connect
    networks:
      - infra-net    
    volumes:
    - kafka-ui-data:/tmp/hsperfdata_kafkaui

  flink-jobmanager:
    image: apache/flink:1.17.1-scala_2.12
    container_name: flink-jobmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    ports:
      - "8081:8081"  # Flink Web UI
    depends_on:
      - kafka
      - zookeeper
    networks:
      - infra-net
    command: jobmanager
    restart: always

  flink-taskmanager:
    image: apache/flink:1.17.1-scala_2.12
    container_name: flink-taskmanager
    environment:
      - JOB_MANAGER_RPC_ADDRESS=flink-jobmanager
    depends_on:
      - flink-jobmanager
    networks:
      - infra-net
    command: taskmanager
    restart: always
      
  zeppelin:
    image: apache/zeppelin:0.10.1
    container_name: zeppelin
    ports:
      - "8089:8080"  # Zeppelin Web UI    
    environment:
    - ZEPPELIN_ADDR=0.0.0.0
    - ZEPPELIN_FLINK_JOBMANAGER_URL=flink-jobmanager:8081  # Flink JobManager REST endpoint URL
    - ZEPPELIN_FLINK_EXECUTION_MODE=remote  # Execution mode set to remote
    - ZEPPELIN_FLINK_EXECUTION_REMOTE_HOST=flink-jobmanager  # JobManager host
    - ZEPPELIN_FLINK_EXECUTION_REMOTE_PORT=8081  # JobManager port    
    - FLINK_HOME=/opt/flink
    depends_on:
      - flink-jobmanager
    networks:
      - infra-net
    volumes:
      - zeppelin-data:/opt/zeppelin
    

volumes:
  postgres-data:
  kafka-logs:
  kafka-ui-data:
  kafka-connect-data:
  zeppelin-data:

networks:
  infra-net:
    driver: bridge
